\section{Regularity proof}

\subsection{Preliminaries}
We start by recalling the definition of regularity \citep{Suzuki2017}:

\begin{definition}
Assume $H_N(X \mid Y') \leq H_N(X \mid Y)$, where $Y' \subset Y.$ We say that the scoring function $Q_N(\cdot \mid \cdot)$ is regular if $Q_N(X \mid Y') \geq Q_N(X \mid Y)$.
\end{definition}
In the definition, $N$ denotes the sample size, $X$ is some random variable, $Y$ denotes the proposed parent set for $X$, and $H_N(X \mid Y)$ refers to the empirical conditional entropy based on $N$ samples of variables $X$ and $Y$.

Let $X$ be a categorical random variable with $r$ possible values. Let $U$ denote a possible parent set with $q$ different combinations of values for the variables, and $V$ a set with $m$ different configurations. Assume that we have observed $N$ samples of $(X,U,V)$ (denoted by $x_N,u_N$ and $v_N$) and $H_N(X \mid U) \leq H_N(X \mid U \cup V)$ holds.

Recall the definition of the qNML score:
\begin{align*}
Q^{qnml}_N(X\mid U) &= \log P(x_N \mid \hat{\theta}_{X\mid U} \ ) - \Le reg(N,rq) - reg(N,q) \Ri \\
&= \log P(x_N \mid \hat{\theta}_{X\mid U} \ ) - \log \frac{C(N,rq)}{C(N,q)},
\end{align*}where $C(N,r)$ is the normalizing constant the of the NML distribution for a categorical variable with $r$ possible values and sample size $N$ and $ \hat{\theta}_{X\mid U}$ denotes the maximum likelihood parameters of the conditional distribution of $X$ given $U$ which are computed from the data $(x_N,u_N)$. 


In order to prove the regularity, we need the following three lemmas:
\begin{lemma}\label{Cpolynom} We can write $C(N,k)$ as a polynomial of $k$, formally
$$
C(N,k) = \sum_{j=1}^N a_j k^j,
$$where $a_j > 0$. 
\end{lemma}
\begin{lemma}\label{MLterms}
Assume $H_N(X \mid Y') \leq H_N(X \mid Y)$, where $Y' \subset Y$. Now $\log P(x_N \mid \hat{\theta}_{X\mid Y} \ ) = \log P(x_N \mid \hat{\theta}_{X\mid Y'} \ )$.
\end{lemma}
\begin{lemma}\label{increasing}
Let $r \in \N, r \geq 2$.  The function $k \mapsto \frac{C(N,rk)}{C(N,k)}$ is increasing for every $k \geq 2$.
\end{lemma}
\noindent We present the proofs of these lemmas in Section \ref{lemmaproofs}.  

\subsection{The main proof}
\begin{theorem}
qNML score is regular.
\end{theorem}
\begin{proof}
We want to show that
$$
Q^{qnml}_N(X\mid U) \geq Q^{qnml}_N(X \mid U \cup V).
$$assuming $H_N(X \mid U) \leq H_N(X \mid U \cup V)$. Using the entropy assumption and Lemma \ref{MLterms} implies that the maximized likelihood terms are equal. In order to prove the claim, it suffices to study the penalty terms, and we want to show that
\begin{align*}
- \Le reg(N,rq) - reg(N,q) \Ri \ &\geq \  -\Le reg(N,rqm) - reg(N,qm) \Ri \\
\log \frac{C(N,rq)}{C(N,q)} \ &\leq \log \frac{C(N,rqm)}{C(N,qm)}.
\end{align*}This holds, since logarithm is an increasing function, and $q \leq qm$, so we can apply Lemma \ref{increasing} to conclude the proof. 


\end{proof}


\subsection{Proofs of lemmas}\label{lemmaproofs}
%We want to show that
%$$
%\quad  Q^{qnml}_N(X\mid U) \geq Q^{qnml}_N(X \mid U \cup V)
%$$which, by using the definition of qNML, is equivalent to 
%\begin{equation}\label{statement}
%\log P(X \mid )
%\end{equation}
%The assumption about entropy implies that the maximized likelihood terms of the qnml-score are equal. 
\setcounter{lemma}{0}
\begin{lemma} $C(N,k)$ can be written as a polynomial of $k$, formally
$$
C(N,k) = \sum_{j=1}^N a_j k^j,
$$where $a_j > 0$. 
\end{lemma}
\begin{proof} \cite{cosco.itsl08} derive the following representation for the normalizing constant
\begin{align*}  
C(N,k) = \sum_{l=0}^{N-1}\frac{(N-1)^{\underline{l}}k^{\overline{l + 1}}}{N^{l+1} \ l!} ,
\end{align*}where $x^{\underline{l}}$ and $x^{\overline{l}}$ denote falling and rising factorials, respectively. 

We utilize the fact that the rising factorial can be represented as polynomial using unsigned Stirling numbers of the first kind (see \cite{Adamchik1997}, for instance)
\begin{align*}
C(N,k) &=  \sum_{l=0}^{N-1}\frac{(N-1)^{\underline{l}}k^{\overline{l + 1}}}{N^{l+1} \ l!} \\
&= \sum_{l=0}^{N-1} b_l \ k^{\overline{l+1}} \\
&= \sum_{l=0}^{N-1} b_l \Le \sum_{j=1}^{l+1}|s(l + 1,j)| \ k^j \Ri \\
&= \sum_{l=0}^{N-1} \Le \sum_{j=1}^{N}b_l \ |s(l + 1,j)| \ k^j \Ri \\
&= \sum_{j=1}^{N} \Le \sum_{l=0}^{N-1} b_l \ |s(l + 1,j)| \ k^j \Ri \\
&= \sum_{j=1}^{N} \Le \sum_{l=0}^{N-1} b_l \ |s(l + 1,j)| \Ri k^j \\
&= \sum_{j=1}^{N} a_j  k^j,
\end{align*}where $s(i,j)$ denotes the (signed) Stirling number of the first kind and
$$
a_j = \Le \sum_{l=0}^{N-1} \frac{(N-1)^{\underline{l}}}{N^{l+1}l!} \ |s(l + 1,j)| \Ri,
$$ $a_j > 0$ for all $j$. On the second row, we denoted $b_l = (N-1)^{\underline{l}}/(N^{l+1} l!)$. On the row 4, we used the property of Stirling numbers: $s(i,j) = 0$ for all $j > i$. 
\end{proof}
\begin{lemma}
Assume $H_N(X \mid Y') \leq H_N(X \mid Y)$, where $Y' \subset Y$. Now $\log P(x_N \mid \hat{\theta}_{X\mid Y} \ ) = \log P(x_N \mid \hat{\theta}_{X\mid Y'})$.
\end{lemma}
\begin{proof}
We can write the logarithm of the maximized likelihood, \\ $\log P(x_N \mid \hat{\theta}_{X\mid Y} \ )$, as follows \citep{KOLLER}
\begin{align*}
\log P(x_N \mid \hat{\theta}_{X\mid Y} \ ) & = -N \Le H_N(X) - I_N(X;Y) \Ri \\
&= -N \  H_N(X\mid Y),
\end{align*}where $I_N(\cdot;\cdot)$ is the empirical mutual information. This implies that the assumption
$$
H_N(X \mid Y') \leq H_N(X \mid Y)
$$ is equivalent to
$$
\log P(x_N \mid \hat{\theta}_{X\mid Y} \ ) \leq \log P(x_N \mid \hat{\theta}_{X\mid Y'} \ ) .
$$Actually we must have the equality holding in the above expression, since
$$
H_N(X \mid Y') < H_N(X \mid Y)
$$ would imply that
$$
I_N(X ; Z \mid Y ) < 0,
$$where $Z = Y \setminus Y'$, which is impossible.
\end{proof}
\begin{lemma}
Let $r \in \N, r \geq 2$.  The function $k \mapsto \frac{C(N,rk)}{C(N,k)}$ is increasing for every $k \geq 2$.
\end{lemma}

\begin{proof}
Lemma \ref{Cpolynom} lets us to write
\begin{equation}\label{C1}
C(N,k) = \sum_{j=1}^{N} a_j k^j
\end{equation}and, similarly,
\begin{equation}\label{C2}
C(N,rk) = \sum_{j=1}^{N} a_j  r^jk^j.
\end{equation}

In the following, we assume that $k$ is a real number. From (\ref{C1}) and (\ref{C2}), it is easy see that the derivative of the quotient, $d/dk (C(N,rk)/C(N,k))$, will be a ratio of two polynomials of $k$. Our goal is to show that the polynomial in the numerator has positive coefficients, which will guarantee the positivity of derivative for every $k > 0$, and thus imply that the original function is increasing (polynomial in the denominator is squared and non-zero for $k > 0$, so it can be ignored).  

Derivatives of (\ref{C1}) and (\ref{C2}) are obtained easily:
\begin{align*}
\frac{d}{dk}C(N,k) &= \sum_{j=1}^{N}ja_jk^{j-1} \\
&= \sum_{j=0}^{N-1}(j+1) a_{j+1}k^{j}
\end{align*}and
\begin{align*}
\frac{d}{dk}C(N,rk) &= \sum_{j=1}^{N}ja_jr^jk^{j-1} \\
&= \sum_{j=0}^{N-1}(j+1)a_{j+1}r^{j+1}k^{j}. 
\end{align*}Consider next the products found in the derivative of the quotient. We obtain
\begin{align*}
\Le\frac{d}{dk}C(N,rk)\Ri C(N,k) &= \Le \sum_{j=0}^{N-1}(j+1)a_{j+1}r^{j+1}k^{j} \Ri \Le \sum_{l=1}^{N} a_l  k^l \Ri \\
&= \sum_{i = 1}^{2N-1} \Le \sum_{j+l = i} (j+1)a_{j+1}r^{j+1}a_l  \Ri k^i
\end{align*}and
%\begin{align*}
%\Le\frac{d}{dk}C(n,k)\Ri C(n,rk) &= \Le \sum_{j=0}^{n-1}(j+1)a_{j+1}k^{j} \Ri \Le %\sum_{l=1}^{n} a_l  r^lk^l  \Ri \\
%&= \sum_{i = 1}^{2n-1} \Le \sum_{m=0}^i (m+1)a_{m+1}a_{i-m}r^{i-m}   \Ri k^i
%\end{align*}
\begin{align*}
\Le\frac{d}{dk}C(N,k)\Ri C(N,rk) &= \Le \sum_{j=0}^{N-1}(j+1)a_{j+1}k^{j} \Ri \Le \sum_{l=1}^{N} a_l  r^lk^l  \Ri \\
&= \sum_{i = 1}^{2N-1} \Le \sum_{j+l = i}(j+1)a_{j+1}a_l  r^l   \Ri k^i.
\end{align*}
Subtracting these two expression yields
\begin{align*}
&\Le\frac{d}{dk}C(N,rk)\Ri C(N,k)-\Le\frac{d}{dk}C(N,k)\Ri C(N,rk) \\&= \sum_{i = 1}^{2N-1} \Le \sum_{j+l = i} (j+1)a_{j+1}r^{j+1}a_l  \Ri k^i - \sum_{i = 1}^{2N-1} \Le \sum_{j+l = i}(j+1)a_{j+1}a_l  r^l   \Ri k^i \\
&= \sum_{i = 1}^{2N-1} \Le \sum_{j+l = i}(j+1)a_{j+1}a_l  (r^{j+1}- r^l)   \Ri k^i
\end{align*}which is the polynomial in the numerator of the derivative of $C(N,rk)/C(N,k)$.
Next, we study the coefficient of $k^i$, if $i \leq N$
\begin{align*}
\sum_{j+l = i}(j+1)a_{j+1}a_l  (r^{j+1}- r^l) &= \sum_{l=1}^{i}(i-l+1)a_{i-l+1}a_l  (r^{i-l+1}- r^l) \\
& = \sum_{l=1}^{i}(i-l+1)c_l \\
&= \sum_{t =1}^{\lfloor i / 2 \rfloor}(i-t+1)c_t + (i-(i-t + 1)+1)c_{i-t+1} \\
&=  \sum_{t =1}^{\lfloor i / 2 \rfloor}(i-t+1)c_t + tc_{i-t+1} \\
&=  \sum_{t =1}^{\lfloor i / 2 \rfloor}(i-t+1)c_t - tc_{t} \\
&= \sum_{t =1}^{\lfloor i / 2 \rfloor}(i-2t+1)c_t.
\end{align*} On the first row, we re-wrote sum using only one running index. On the second row we denoted $c_l =a_{i-l+1}a_l  (r^{i-l+1}- r^l)$. On the third row, we re-arranged the sum so that we are summing over pairs of terms of the original sum: the first and the last term, the second and the second to last, and so on.  This resulting sum has $\lfloor i / 2 \rfloor$ terms. We have to use the floor-function since if $i$ is odd, there exists an index $l'$ in the original sum such that $r^{i-l'+1}-r^{l'} = 0$. On the fifth row, we make use of the identity $c_t = -c_{i-t+1}$ which is straightforward to verify. From the last row, we can observe that every term of the sum is positive since $i-2t+1$ and $r^{i-t+1}- r^t$ are both positive if $t \leq (i+1)/2$ which holds since $t$ ranges from $1$ to $\lfloor i / 2 \rfloor$.

Let us now consider the situation where $n < i \leq 2N-1$. We start with the special case where $i = 2N-1$. Then, we have only one term in the sum
\begin{align*}
\sum_{j+l = i}(j+1)a_{j+1}a_l  (r^{j+1}- r^l) &= \sum_{l=N}^{N}(2N-1-l+1)a_{2N-1-l+1}a_l  (r^{2N-1-l+1}- r^l) \\
&= Na_{N}a_N  (r^{N}- r^N) \\
& = 0.
\end{align*}Now, let $N < i < 2N-1$, we follow a similar procedure as before to manipulate the sum
\begin{align*}
\sum_{j+l = i}(j+1)a_{j+1}a_l  (r^{j+1}- r^l) &= \sum_{l=i-N + 1}^{N}(i-l+1)a_{i-l+1}a_l  (r^{i-l+1}- r^l) \\
& = \sum_{l=i-N + 1}^{N}(i-l+1)c_l \\
& = \sum_{t=1}^{2N-i}(N-t+1)c_{i-N+t} \\
& = \sum_{t=1}^{\lfloor N - i/2 \rfloor}(N-t+1)c_{i-N+t}\\
&+  (N-(2N-i-t+1)+1)c_{i-N+(2N-i-t+1)} \\
&= \sum_{t=1}^{\lfloor N - i/2 \rfloor}(N-t+1)c_{i-N+t} +  (i-N+t)c_{N-t+1} \\
&= \sum_{t=1}^{\lfloor N - i/2 \rfloor}(N-t+1)c_{i-N+t} -  (i-N+t)c_{i-N+t} \\
&= \sum_{t=1}^{\lfloor N - i/2 \rfloor}(N-t+1-(i-N+t))c_{i-N+t} \\
&= \sum_{t=1}^{\lfloor N - i/2 \rfloor}(2N-i-2t+1)c_{i-N+t}.
\end{align*}It is now easy to verify that $(2N-i-2t+1)$ and $c_{i-N+t}$ are positive if $t \leq N - (i-1)/2$ which holds since $t$ ranges from $1$ to $\lfloor N - i/2 \rfloor$. The floor function is again used when we sum over pairs of terms since if $i$ is odd there is a zero-term. 
Since all the coefficients are non-negative and the $k \geq 2$, the derivative is positive. This implies that the original function is increasing.
\end{proof}


\subsection{fNML is Regular}
In this section, we will show that fNML score is regular. Recall first the definition of fNML local score
\begin{equation}
Q^{fnml}_N(X  \vert \ U) = \log P(x_N \mid \hat{\theta}_{X\mid U} \ ) - \sum_{j = 1}^{r_U} reg(N_j,r_X),
\end{equation}where $r_X$ is the number of categories for $X$, $r_U$ denotes the number of possible configurations of variables in $U$, and $N_j$ is the number of times the $j^\text{th}$ configuration is observed in our samples $u_N$. Note that $reg(N_j,r_X) = 0$ for any configuration not observed in our sample. 
fNML criterion differs from qNML only by how the penalty term is defined. We can follow a highly similar strategy in order to prove the regularity for fNML. To this end, we need the following Lemma:
\begin{lemma}\label{regineq}
Let $N = N_1 + N_2$ and $r \in\N, r \geq 2$. Now,
$$
reg(N,r) \leq reg(N_1,r) + reg(N_2,r).
$$
\end{lemma}
\begin{proof}
We start with the definition of $C(N_1,r) = \exp(reg(N_1,r))$,
\begin{align*}
C(N_1,r)C(N_2,r) &= \sum_{x_{N_1}}P(x_{N_1} \vert \hat{\theta}(x_{N_1} ))\sum_{x_{N_2}}P(x_{N_2} \vert \hat{\theta}(x_{N_2} ))\\ & \geq
\sum_{x_{N_1}}P(x_{N_1} \vert \hat{\theta}(x_{N} ))\sum_{x_{N_2}}P(x_{N_2} \vert \hat{\theta}(x_{N} )) \\ &=
\sum_{x_{N}}P(x_{N} \vert \hat{\theta}(x_{N} )) \\ & = C(N,r).
\end{align*}Taking the logarithm on both sides yields our claim. On the second row, we used the definition of maximum likelihood parameters: the probability of the data vector $x_{N_1}$ is maximized under parameters $\hat{\theta}(x_{N_1})$, and if we use different parameters, $\hat{\theta}(x_{N_1})$, the probability can only go down or stay the same. On the third row, we used the i.i.d., assumption, which allows us to take the single sum over data vectors of length $N = N_1 + N_2$.
\end{proof}
Now we can proceed to the actual proof.
\begin{theorem}
fNML score is regular.
\end{theorem}
\begin{proof}
Using the entropy assumption and Lemma \ref{C2}, we can ignore the maximized likelihood terms and study the penalty terms. We want show that
\begin{equation}\label{fnmlPenalty}
\sum_{j = 1}^{r_{Y'}} reg(N'_j,r_X) \leq \sum_{l = 1}^{r_{Y}} reg(N_l,r_X),
\end{equation}where we used $r_{Y'}$ and $r_Y$ to denote the numbers of possible configurations for variables in $Y'$ and $Y$, respectively. Also, $N_j$ refers to the number times the $j$:th configuration of variables $Y$ is observed in our sample, and $N'_j$ denotes the same for $Y'$. 

Now, since $r_{Y'} \leq r_Y$, and we know that $\sum_j N'_j = \sum_l N_l = N$, we can just apply Lemma (\ref{regineq}) multiple times to conclude our proof. 
\end{proof}


